---
title: "HW3"
format: html
editor: visual
---

### Github URL: https://github.com/aelbass/STATS506_HW1.git

## Problem 1

### a. Read data

```{r}
library(haven)
library(dplyr)

data <- read_xpt("AUX_I.xpt")
data2 <- read_xpt("DEMO_I.xpt")


merged <- inner_join(data, data2, by = "SEQN")
dim(merged)
```


### b. Clean up data


```{r}
#Clean up gender
unique(merged$RIAGENDR)
merged$RIAGENDR <- factor(merged$RIAGENDR,
                      levels = c(1, 2),
                      labels = c("male", "female"))
unique(merged$RIAGENDR)
```

Gender data is already clean; I just categorized to male and female.


```{r}
#Clean up citizenship

merged$DMDCITZN[!merged$DMDCITZN %in% c(1, 2, 7, 9)] <- NA

merged$DMDCITZN <- factor(merged$DMDCITZN,
                          levels = c(1, 2, 7, 9),
                          labels = c("citizen", "non-citizen", "refused", "don't know"))

library(forcats)
merged$DMDCITZN <- fct_explicit_na(merged$DMDCITZN, na_level = "missing")

unique(merged$DMDCITZN)
table(merged$DMDCITZN)
```

Cleaned up citizenship status and turned into factor with categorical levels.


```{r}
#Clean up children under the age of 5 data
unique(merged$DMDHHSZA)
```

Children under the age of 5 data is already clean and not categorical.


```{r}
#Clean up annual household income
library(dplyr)

merged <- merged %>%
  mutate(INDHHIN2 = case_when(
    INDHHIN2 == 12 ~ 14,
    INDHHIN2 == 14 ~ 11,
    INDHHIN2 == 15 ~ 12,
    TRUE ~ INDHHIN2  # keep everything else unchanged
  ))

table(merged$INDHHIN2)
```


I changed up the ordering of the categories: I made the "0 to 4,999", "5,000 to 9,999", etc. take 1-12 (including 11) for code or value, "Under $20,000" take 13, "20,000 and Over" take 14. There was no missing data.


### c. Poisson regression models predicting a respondentâ€™s Tympanometric width in each ear

```{r}
# cleaning up everything and getting only important data now

library(dplyr)

merged <- merged %>%
  rename(
    Gender = RIAGENDR,
    Citizenship = DMDCITZN,
    NumKids_U5 = DMDHHSZA,
    HouseholdIncome = INDHHIN2,
    Right_ear = AUXTWIDR,
    Left_ear = AUXTWIDL
  )

merged <- merged %>%
  select(SEQN, Gender, Citizenship, NumKids_U5, HouseholdIncome, Right_ear, Left_ear)

library(broom)
library(knitr)

# Model 1R
model_1R <- glm(Right_ear ~ Gender, family = poisson(link = "log"), data = merged)

# Model 2R
model_2R <- glm(Right_ear ~ Gender + Citizenship + NumKids_U5 + HouseholdIncome,
                family = poisson(link = "log"), data = merged)

# Model 1L
model_1L <- glm(Left_ear ~ Gender, family = poisson(link = "log"), data = merged)

# Model 2L
model_2L <- glm(Left_ear ~ Gender + Citizenship + NumKids_U5 + HouseholdIncome,
                family = poisson(link = "log"), data = merged)

# Function to get tidy table with IRRs
get_IRR_table <- function(model) {
  tidy(model) %>%
    mutate(IRR = exp(estimate),
           IRR_lower = exp(estimate - 1.96*std.error),
           IRR_upper = exp(estimate + 1.96*std.error)) %>%
    select(term, IRR, IRR_lower, IRR_upper, p.value) %>%
    mutate(IRR = round(IRR, 3),
           IRR_lower = round(IRR_lower, 3),
           IRR_upper = round(IRR_upper, 3),
           p.value = round(p.value, 3))
}

# Create IRR tables
irr_1R <- get_IRR_table(model_1R)
irr_2R <- get_IRR_table(model_2R)
irr_1L <- get_IRR_table(model_1L)
irr_2L <- get_IRR_table(model_2L)

get_model_stats <- function(model) {
  n <- model$df.null + 1
  aic <- AIC(model)
  
  pseudo_r2 <- 1 - (model$deviance / model$null.deviance)
  
  data.frame(
    N = n,
    Pseudo_R2 = round(pseudo_r2, 3),
    AIC = round(aic, 2)
  )
}

stats_1R <- get_model_stats(model_1R)
stats_2R <- get_model_stats(model_2R)
stats_1L <- get_model_stats(model_1L)
stats_2L <- get_model_stats(model_2L)

#Coefficients
irr_combined <- list(
  "Right Ear: Gender" = irr_1R,
  "Right Ear: Full" = irr_2R,
  "Left Ear: Gender" = irr_1L,
  "Left Ear: Full" = irr_2L
)

# Print with kable
for(name in names(irr_combined)) {
  cat("\n###", name, "\n")
  print(kable(irr_combined[[name]], caption = paste("IRRs for", name)))
}

#Statistics
stats_combined <- bind_rows(
  cbind(Model = "Right Ear: Gender", stats_1R),
  cbind(Model = "Right Ear: Full", stats_2R),
  cbind(Model = "Left Ear: Gender", stats_1L),
  cbind(Model = "Left Ear: Full", stats_2L)
)

kable(stats_combined, caption = "Poisson Model Statistics")

```


### d. Difference between males and females in terms of their incidence risk ratio

```{r}
# I will run summary to get the full value of P.

coef_matrix <- summary(model_2L)$coefficients
coef_matrix["Genderfemale", ]
```

The predicted Tympanometric width of the left ear differs slightly between males and females. Females are expected to have ~1.3% higher width than males, holding all other variables constant. The difference is statistically significant (p = 0.000157).


## Problem 2

### a. Customers in store, and percentage of customers of that store are active in the system

```{r}
library(DBI)
library(RSQLite)

# connect to the database
sakila <- dbConnect(RSQLite::SQLite(), "sakila_master.db")
df <- dbGetQuery(sakila, "
  SELECT s.store_id, c.customer_id, c.active
  FROM store s
  LEFT JOIN customer c
  ON s.store_id = c.store_id
")

library(dplyr)

df <- df %>%
  mutate(active = as.numeric(active))

result_r <- df %>%
  group_by(store_id) %>%
  summarise(
    total_customers = n(),
    active_customers = sum(active, na.rm = TRUE),
    pct_active = 100 * active_customers / total_customers
  )

print(result_r)

#fully in SQL

result_sql <- dbGetQuery(sakila, "
  SELECT
    s.store_id,
    COUNT(c.customer_id) AS total_customers,
    SUM(c.active) AS active_customers,
    100.0 * SUM(c.active) / COUNT(c.customer_id) AS pct_active
  FROM store s
  LEFT JOIN customer c ON s.store_id = c.store_id
  GROUP BY s.store_id
")

print(result_sql)
```

Speed analysis with microbenchmark

```{r}
library(DBI)
library(RSQLite)
library(microbenchmark)

# connect to the database
sakila <- dbConnect(RSQLite::SQLite(), "sakila_master.db")

mb <- microbenchmark(
  R_based = {
    df <- dbGetQuery(sakila, "
      SELECT s.store_id, c.customer_id, c.active
      FROM store s
      LEFT JOIN customer c
      ON s.store_id = c.store_id
    ")

    df <- df %>%
      mutate(active = as.numeric(active)) %>%
      group_by(store_id) %>%
      summarise(
        total_customers = n(),
        active_customers = sum(active, na.rm = TRUE),
        pct_active = 100 * active_customers / total_customers,
        .groups = "drop"
      )
  },
  
  SQL_based = {
    dbGetQuery(sakila, "
      SELECT
        s.store_id,
        COUNT(c.customer_id) AS total_customers,
        SUM(c.active) AS active_customers,
        100.0 * SUM(c.active) / COUNT(c.customer_id) AS pct_active
      FROM store s
      LEFT JOIN customer c ON s.store_id = c.store_id
      GROUP BY s.store_id
    ")
  },
  
  times = 10
)

print(mb)
```
The SQL_based function is about 10 times faster than getting the data into R and running R functions on it.

### b. Table identifying the names and country of each staff member

```{r}
library(DBI)
library(RSQLite)
library(dplyr)
library(microbenchmark)

# Connect to the database
sakila <- dbConnect(RSQLite::SQLite(), "sakila_master.db")

staff_df <- dbGetQuery(sakila, "SELECT staff_id, first_name, last_name, address_id FROM staff;")
address_df <- dbGetQuery(sakila, "SELECT address_id, city_id FROM address;")
city_df <- dbGetQuery(sakila, "SELECT city_id, country_id FROM city;")
country_df <- dbGetQuery(sakila, "SELECT country_id, country FROM country;")

# Join in R
result_r <- staff_df %>%
  left_join(address_df, by = "address_id") %>%
  left_join(city_df, by = "city_id") %>%
  left_join(country_df, by = "country_id") %>%
  select(first_name, last_name, country)


result_sql <- dbGetQuery(sakila, "
  SELECT 
    s.first_name,
    s.last_name,
    co.country
  FROM staff s
  LEFT JOIN address a ON s.address_id = a.address_id
  LEFT JOIN city ci ON a.city_id = ci.city_id
  LEFT JOIN country co ON ci.country_id = co.country_id;
")

library(knitr)
kable(result_r, caption = "R-Based Approach: Staff Names and Country")

kable(result_sql, caption = "SQL-Based Approach: Staff Names and Country")
```


Speed analysis with microbenchmark

```{r}
mb <- microbenchmark(
  R_based = {
    staff_df <- dbGetQuery(sakila, "SELECT staff_id, first_name, last_name, address_id FROM staff;")
    address_df <- dbGetQuery(sakila, "SELECT address_id, city_id FROM address;")
    city_df <- dbGetQuery(sakila, "SELECT city_id, country_id FROM city;")
    country_df <- dbGetQuery(sakila, "SELECT country_id, country FROM country;")

    staff_df %>%
      left_join(address_df, by = "address_id") %>%
      left_join(city_df, by = "city_id") %>%
      left_join(country_df, by = "country_id") %>%
      select(first_name, last_name, country)
  },

  SQL_based = {
    dbGetQuery(sakila, "
      SELECT 
        s.first_name,
        s.last_name,
        co.country
      FROM staff s
      LEFT JOIN address a ON s.address_id = a.address_id
      LEFT JOIN city ci ON a.city_id = ci.city_id
      LEFT JOIN country co ON ci.country_id = co.country_id;
    ")
  },

  times = 5
)

print(mb)
```

The SQL based function is roughly 16 times faster than importing and running in R.

### c. Name(s) of the film(s) which was/were rented for the highest dollar value

```{r}
library(dplyr)

film <- dbReadTable(sakila, "film")
inventory <- dbReadTable(sakila, "inventory")
rental <- dbReadTable(sakila, "rental")
payment <- dbReadTable(sakila, "payment")

result_r <- film %>%
  left_join(inventory, by = "film_id", relationship = "many-to-many") %>%
  left_join(rental, by = "inventory_id", relationship = "many-to-many") %>%
  left_join(payment, by = "rental_id", relationship = "many-to-many") %>%
  group_by(title) %>%
  summarise(total_revenue = sum(amount, na.rm = TRUE)) %>%
  arrange(desc(total_revenue)) %>%
  slice_head(n = 3)

print(result_r)

result_sql <- dbGetQuery(sakila, "
  SELECT f.title AS film_title,
         SUM(p.amount) AS total_revenue
  FROM film f
  JOIN inventory i ON f.film_id = i.film_id
  JOIN rental r ON i.inventory_id = r.inventory_id
  JOIN payment p ON r.rental_id = p.rental_id
  GROUP BY f.title
  ORDER BY total_revenue DESC
  LIMIT 3;
")

print(result_sql)
```
The highest 3 films with dollar values are: TELEGRAPH VOYAGE, WIFE TURN and ZORRO ARK.


Speed analysis with microbenchmark.

```{r}
library(microbenchmark)

microbenchmark(
  R_based = {
    film <- dbReadTable(sakila, "film")
    inventory <- dbReadTable(sakila, "inventory")
    rental <- dbReadTable(sakila, "rental")
    payment <- dbReadTable(sakila, "payment")

    film %>%
  left_join(inventory, by = "film_id", relationship = "many-to-many") %>%
  left_join(rental, by = "inventory_id", relationship = "many-to-many") %>%
  left_join(payment, by = "rental_id", relationship = "many-to-many") %>%
      group_by(title) %>%
      summarise(total_revenue = sum(amount, na.rm = TRUE)) %>%
      arrange(desc(total_revenue)) %>%
      slice_head(n = 3)
  },
  SQL_based = {
    dbGetQuery(sakila, "
      SELECT f.title AS film_title,
             SUM(p.amount) AS total_revenue
      FROM film f
      JOIN inventory i ON f.film_id = i.film_id
      JOIN rental r ON i.inventory_id = r.inventory_id
      JOIN payment p ON r.rental_id = p.rental_id
      GROUP BY f.title
      ORDER BY total_revenue DESC
      LIMIT 3;
    ")
  },
  times = 10
)
```

## Problem 3

### a. Percentage of the websites .comâ€™s

```{r}
data <- read.csv("au-500.csv")

data %>%
  summarize(
    percent_com = mean(grepl("\\.com$", web, ignore.case = TRUE)) * 100
  )
```


### b. Most common domain name

```{r}
options(repos = c(CRAN = "https://cloud.r-project.org"))
install.packages("stringr")
install.packages("dplyr")

library(dplyr)
library(stringr)

data %>%
  mutate(domain = str_extract(email, "(?<=@).*")) %>%
  count(domain, sort = TRUE) %>%
  slice(1)
```


### c. Proportion of company names with non-alphabertical characters

```{r}
data %>%
  summarize(
    prop_non_alpha = mean(str_detect(company_name, "[^A-Za-z,[:space:]]"))
  )
# if I aslo exclude &

data %>%
  summarize(
    prop_non_alpha2 = mean(str_detect(company_name, "[^A-Za-z,[:space:]&]"))
  )
```


### d. Turn landline numbers to cell phone format

```{r}
data$phone1 <- as.character(data$phone1)
data$phone2 <- as.character(data$phone2)

# Format phone1 (landlines) into cell phone format: 1234-567-890
data$phone1 <- gsub(
  "^([0-9]{4})([0-9]{3})([0-9]{3})$", 
  "\\1-\\2-\\3", 
  gsub("[^0-9]", "", data$phone1) # remove any non-digit characters
)

data$phone2 <- gsub(
  "^([0-9]{4})([0-9]{3})([0-9]{3})$", 
  "\\1-\\2-\\3", 
  gsub("[^0-9]", "", data$phone2)
)

# Show the first 10 numbers from each column
head(data$phone1, 10)
head(data$phone2, 10)
```
Cell-phone (phone2) numbers are already in the right format. 


### e. Histogram of Apt. numbers

```{r}
apt_numbers <- as.numeric(sub(".*#(\\d+)\\s*$", "\\1", data$address))
log_apt <- log(apt_numbers)

hist(log_apt,
     main = "Histogram of log(Apartment Numbers)",
     xlab = "log(Apartment Number)",
     ylab = "Frequency",
     col = "skyblue",
     border = "white")
```


### f. Aprtment numbers following Benford's law

```{r}
first_digit <- as.numeric(substr(as.character(apt_numbers), 1, 1))
digit_counts <- table(factor(first_digit, levels=1:9))
digit_props <- digit_counts / sum(digit_counts)

# Print proportions
digit_props
```

Since Benford's law states that the number 1 appears as the leading significant digit about 30% of the time, while 9 appears as the leading significant digit less than 5% of the time, the apartment numbers does not pass as real data with the number 1 appearing only 9.6% of times and number 9 appearing 13.6%. 

