---
title: "HW2"
format: html
editor: visual
---

### Github URL: https://github.com/aelbass/STATS506_HW1.git

## Problem 1

### a. Position after steps

```{r}
#' random_walk1 function (loop)
#'
#' @param n the number of steps
#' @return The final position of the walk
#' @export
random_walk1 <- function(n_steps) {
  steps <- sample(c(1, -1), n_steps, replace = TRUE)
  pos_unifs <- runif(n_steps)
  neg_unifs <- runif(n_steps)
  
  position <- 0
  
  for (i in 1:n_steps) {
    step <- steps[i]
    
    if (step == 1) {
      if (pos_unifs[i] < 0.05) {
        move <- 10
      } else {
        move <- 1
      }
    } else {
      if (neg_unifs[i] < 0.20) {
        move <- -3
      } else {
        move <- -1
      }
    }
    
    position <- position + move
  }
  
  return(position)
}

#' random_walk2 function (vectorization)
#'
#' @param n the number of steps
#' @return The final position of the walk
#' @export


random_walk2 <- function(n_steps) {
  sum(ifelse(
    sample(c(1, -1), n_steps, replace = TRUE) == 1,
    ifelse(runif(n_steps) < 0.05, 10, 1),
    ifelse(runif(n_steps) < 0.20, -3, -1)
  ))
}

random_walk3 <- function(n_steps) {
  steps <- sample(c(1, -1), n_steps, replace = TRUE)
  pos_unifs <- runif(n_steps)
  neg_unifs <- runif(n_steps)
  
  moves <- sapply(1:n_steps, function(i) {
    step <- steps[i]
    if (step == 1) {
      if (pos_unifs[i] < 0.05) 10 else 1
    } else {
      if (neg_unifs[i] < 0.20) -3 else -1
    }
  })
  sum(moves)
}

random_walk1(10)
random_walk2(10)
random_walk3(10)
random_walk1(1000)
random_walk2(1000)
random_walk3(1000)
```

### b.Using seed = 25

```{r}
set.seed(25)
random_walk1(10)
set.seed(25)
random_walk2(10)
set.seed(25)
random_walk3(10)
set.seed(25)
random_walk1(1000)
set.seed(25)
random_walk2(1000)
set.seed(25)
random_walk3(1000)
```

### c. Timing compariosn

```{r}
# I made this new vectorized version that runs faster to see the difference in speed. My first vectorized function runs slower than expected.

random_walk22 <- function(n_steps) {
  steps <- sample(c(1L, -1L), n_steps, replace = TRUE)
  unifs <- runif(n_steps)
  
  moves <- integer(n_steps)
  moves[] <- steps  # Copy steps as base moves
  moves[steps == 1L & unifs < 0.05] <- 10L
  moves[steps == -1L & unifs < 0.20] <- -3L
  
  sum(moves)
}

# Benchmark
library("microbenchmark")


microbenchmark(
  loop = random_walk1(1000),
  vectorized = random_walk22(1000),
  sapply = random_walk3(1000),
  times = 1000
)
```


At a 1000 steps, the vectorized version is twice as fast as the loop version. The sapply version is very slow at 467ms. 

### at 100000 steps

```{r}
microbenchmark(
  loop = random_walk1(100000),
  vectorized = random_walk22(100000),
  sapply = random_walk3(100000),
  times = 1000
)
```

At a 100000 steps, all functions are actually faster then when only 1000 steps were taken. This can be due to the fact that the function overhead is not counted in the time computation and the time calculation is dominated by the algorithimic efficiency. The vectorized version is also twice as fast as the loop version. The sapply version is slow at 48ms. 


### d. Probability of landing at 0

```{r}
set.seed(25)
n_sim <- 100000

# 10 steps
results_10 <- replicate(n_sim, random_walk2(10))
prob_10 <- mean(results_10 == 0)

# 100 steps  
results_100 <- replicate(n_sim, random_walk2(100))
prob_100 <- mean(results_100 == 0)

# 1000 steps
results_1000 <- replicate(n_sim, random_walk2(1000))
prob_1000 <- mean(results_1000 == 0)

cat("Monte Carlo Results (n = 100,000 simulations):\n")
cat("Probability of ending at 0 after 10 steps: ", round(prob_10, 5), "\n")
cat("Probability of ending at 0 after 100 steps: ", round(prob_100, 5), "\n")
cat("Probability of ending at 0 after 1000 steps: ", round(prob_1000, 5), "\n")
```

For 10 steps, the probability of ending at 0 is 13.3%. For 100 steps, the probability of ending at 0 is 1.9%. For 1000 steps, the probability of ending at 0 is 0.6%. 

We see that the walk is more probably to end at 0 with 10 steps than with a 1000 steps. This is due to the fact that for 10 steps, the distribution is relatively compact, so there's a reasonable chance of returning to 0. However, for 1000 steps, the walk has explored a much wider range, making exact return to 0 very unlikely.


## Problem 2

```{r}
N <- 3650  # number of days in 10 years

# Poisson means for 24 hours
lam <- rep(0, 24)
lam[1:8]   <- 1   # hours 0–7
lam[10:17] <- 8   # hours 9–16
lam[19:24] <- 12  # hours 18–23

# Poisson samples (N x 24 matrix)
poisson_samples <- matrix(
  rpois(N * 24, lambda = rep(lam, each = N)),
  nrow = N, ncol = 24, byrow = FALSE
)

# Normal samples for rush hours (8AM and 5PM)
sd <- sqrt(12)
normal_samples <- matrix(
  rnorm(N * 2, mean = 60, sd = sd),
  ncol = 2, byrow = TRUE
)

# Round + clip negatives, stay as matrix
normal_samples <- pmax(0, round(normal_samples))

# Make sure it's still a matrix even if N=1
if (is.null(dim(normal_samples))) {
  dim(normal_samples) <- c(N, 2)
}

# Replace into hour 8 (col 9) and hour 17 (col 18)
poisson_samples[, 9]  <- normal_samples[, 1]
poisson_samples[, 18] <- normal_samples[, 2]

daily_totals <- rowSums(poisson_samples)
mean_daily <- mean(daily_totals)
sd_daily   <- sd(daily_totals)

list(
  mean_daily = mean_daily,
  sd_daily   = sd_daily
)
```
The average number of cars that pass that intersection per day is ~264 +- 13 cars.


## Problem 3

### a. Deidentify data

```{r}
youtube <- read.csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-03-02/youtube.csv')
dim(youtube)
colnames(youtube)
youtube1 <- youtube[, -c( 2, 3, 4, 12, 14, 20, 21, 22, 23,24)]
dim(youtube1)
colnames(youtube1)
head(youtube1)
```

I removed all identifiers from the list, the matrix became 247 rows and down to 15 columns from an initial 25-column matrix.

### b. Variables to be used in regression models

```{r}
hist(youtube1$view_count)
summary(youtube1$view_count)
hist(youtube1$like_count)
summary(youtube1$like_count)
hist(youtube1$dislike_count)
summary(youtube1$dislike_count)
hist(youtube1$favorite_count)
summary(youtube1$favorite_count)
hist(youtube1$comment_count)
summary(youtube1$comment_count)
```

Favorite count could not be appropriate to use as the outcome in a linear regression model since all the values are 0 (maybe binary). All other variables could be used as is as the outcome in a linear regression model.


### c. Linear regression models

```{r}
#views
model_views <- lm(view_count ~ funny + show_product_quickly + patriotic + celebrity +
                  danger + animals + use_sex + year, data = youtube1)

summary(model_views)

#likes
model_likes <- lm(like_count ~ funny + show_product_quickly + patriotic + celebrity +
                  danger + animals + use_sex + year, data = youtube1)

summary(model_likes)

#dislikes
model_dislikes <- lm(dislike_count ~ funny + show_product_quickly + patriotic +    celebrity + danger + animals + use_sex + year, data = youtube1)

summary(model_dislikes)

#comments
model_comments <- lm(comment_count ~ funny + show_product_quickly + patriotic + celebrity + danger + animals + use_sex + year, data = youtube1)

summary(model_comments)
```

For the view, like and dislike counts, there is no statistcial difference based on the p-values > 0.05, thus no consistent effect between any of the binary variables and the counts.

However, for the comment counts there is a directly positive relationship between patriotic adds and comments with a p value of 0.035. This is the only statistically significantly relationship. 


### d. Compute B hat manually

```{r}
# setting up proper matrix
vars_used <- c("view_count", "funny", "show_product_quickly", "patriotic", "celebrity",
               "danger", "animals", "use_sex", "year")
complete_cases <- complete.cases(youtube1[, vars_used])
youtube_complete <- youtube1[complete_cases, ]

X <- model.matrix(view_count ~ funny + show_product_quickly + patriotic + celebrity +
                 danger + animals + use_sex + year, data = youtube_complete)

y <- youtube_complete$view_count

cat("Dimensions of X:", dim(X), "\n")
cat("Length of y:", length(y), "\n")
cat("Number of rows in X equals length of y:", nrow(X) == length(y), "\n")

beta_hat_manual <- solve(crossprod(X), crossprod(X, y))
beta_hat_manual
```

These are same values of B obtained in part C when lm was used.
