---
title: "HW2"
format: html
editor: visual
---

### Github URL: https://github.com/aelbass/STATS506_HW1.git

## Problem 1

### trying random_walk function
```{r}
#' random_walk function
#'
#' @param n the number of steps
#' @return The final position of the walk
#' @export
random_walk <- function(n_steps) {
  position <- 0
  
  for (i in 1:n_steps) {
    step <- sample(c(-1, 1), 1)  # base direction, 50/50
    
    if (step == 1) {
      # With 5% chance, replace +1 with +10
      if (runif(1) < 0.05) {
        move <- 10
      } else {
        move <- 1
      }
    } else {
      # With 20% chance, replace -1 with -3
      if (runif(1) < 0.20) {
        move <- -3
      } else {
        move <- -1
      }
    }
    
    position <- position + move
  }
  
  return(position)
}
random_walk(10)
random_walk(10)
```


### a.

```{r}
#' random_walk1 function (loop)
#'
#' @param n the number of steps
#' @return The final position of the walk
#' @export
random_walk1 <- function(n_steps) {
  position <- 0
  
  for (i in 1:n_steps) {
    step <- sample(c(-1, 1), 1)  # base direction, 50/50
    
    if (step == 1) {
      # With 5% chance, replace +1 with +10
      if (runif(1) < 0.05) {
        move <- 10
      } else {
        move <- 1
      }
    } else {
      # With 20% chance, replace -1 with -3
      if (runif(1) < 0.20) {
        move <- -3
      } else {
        move <- -1
      }
    }
    
    position <- position + move
  }
  
  return(position)
}

#' random_walk2 function (vectorization)
#'
#' @param n the number of steps
#' @return The final position of the walk
#' @export

random_walk2 <- function(n_steps) {
  sum(ifelse(
    sample(c(1, -1), n_steps, replace = TRUE) == 1,
    ifelse(runif(n_steps) < 0.05, 10, 1),
    ifelse(runif(n_steps) < 0.20, -3, -1)
  ))
}

random_walk4 <- function(n_steps) {
  # Generate all random numbers in the same sequence as the loop
  rand_nums <- runif(2 * n_steps)  # 2 random numbers per step
  
  # Extract direction and modifier random numbers
  direction_rand <- rand_nums[seq(1, 2*n_steps, by = 2)]
  modifier_rand <- rand_nums[seq(2, 2*n_steps, by = 2)]
  
  directions <- ifelse(direction_rand < 0.5, 1, -1)
  
  increments <- ifelse(
    directions == 1,
    ifelse(modifier_rand < 0.05, 10, 1),
    ifelse(modifier_rand < 0.20, -3, -1)
  )
  
  sum(increments)
}

#' random_walk3 function (apply)
#'
#' @param n the number of steps
#' @return The final position of the walk
#' @export

random_walk3 <- function(n_steps) {
  moves <- sapply(1:n_steps, function(i) {
    step <- sample(c(-1, 1), 1)
    if (step == 1) {
      if (runif(1) < 0.05) 10 else 1
    } else {
      if (runif(1) < 0.20) -3 else -1
    }
  })
  sum(moves)
}

random_walk1(10)
random_walk2(10)
random_walk3(10)
random_walk1(1000)
random_walk2(1000)
random_walk3(1000)
```

### b.Using seed = 25

```{r}
set.seed(25)
random_walk1(10)
set.seed(25)
random_walk2(10)
set.seed(25)
random_walk3(10)
set.seed(25)
random_walk1(1000)
set.seed(25)
random_walk2(1000)
set.seed(25)
random_walk3(1000)
```

### c. timing compariosn

```{r}
# Benchmark
library("microbenchmark")

microbenchmark(
  loop = random_walk1(1000),
  vectorized = random_walk2(1000),
  sapply = random_walk3(1000),
  times = 10
)
```

At a 1000 steps, the vectorized version is much faster at 75ms vs 2454ms for the loop version. The sapply version is slow at 2773ms. The sapply function is probably statistically indifferent from the loop function.

### 100000

```{r}
microbenchmark(
  loop = random_walk1(100000),
  vectorized = random_walk2(100000),
  sapply = random_walk3(100000),
  times = 10
)
```

At a 100000 steps, all functions are actually faster then when only 1000 steps were taken. This can be due to the fact that the function overhead is not counted in the time computation and the time calculation is dominated by the algorithimic efficiency. The vectorized version is much faster at 6ms vs 280ms for the loop version. The sapply version is slow at 339ms. The sapply function is probably statistically indifferent from the loop function.


### d.

```{r}
set.seed(25)
n_sim <- 100000

# 10 steps
results_10 <- replicate(n_sim, random_walk2(10))
prob_10 <- mean(results_10 == 0)

# 100 steps  
results_100 <- replicate(n_sim, random_walk2(100))
prob_100 <- mean(results_100 == 0)

# 1000 steps
results_1000 <- replicate(n_sim, random_walk2(1000))
prob_1000 <- mean(results_1000 == 0)

cat("Monte Carlo Results (n = 100,000 simulations):\n")
cat("Probability of ending at 0 after 10 steps: ", round(prob_10, 5), "\n")
cat("Probability of ending at 0 after 100 steps: ", round(prob_100, 5), "\n")
cat("Probability of ending at 0 after 1000 steps: ", round(prob_1000, 5), "\n")
```
For 10 steps, the probability of ending at 0 is 13.3%. For 100 steps, the probability of ending at 0 is 1.9%. For 1000 steps, the probability of ending at 0 is 0.6%. 
We see that the walk is more probably to end at 0 with 10 steps than with a 1000 steps. This is due to the fact that for 10 steps, the distribution is relatively compact, so there's a reasonable chance of returning to 0. However, for 1000 steps, the walk has explored a much wider range, making exact return to 0 very unlikely.


## Problem 2

```{r}
N <- 3650  # number of days in 10 years

# Poisson means for 24 hours
lam <- rep(0, 24)
lam[1:8]   <- 1   # hours 0–7
lam[10:17] <- 8   # hours 9–16
lam[19:24] <- 12  # hours 18–23

# Poisson samples (N x 24 matrix)
poisson_samples <- matrix(
  rpois(N * 24, lambda = rep(lam, each = N)),
  nrow = N, ncol = 24, byrow = FALSE
)

# Normal samples for rush hours (8AM and 5PM)
sd <- sqrt(12)
normal_samples <- matrix(
  rnorm(N * 2, mean = 60, sd = sd),
  ncol = 2, byrow = TRUE
)

# Round + clip negatives, stay as matrix
normal_samples <- pmax(0, round(normal_samples))

# Make sure it's still a matrix even if N=1
if (is.null(dim(normal_samples))) {
  dim(normal_samples) <- c(N, 2)
}

# Replace into hour 8 (col 9) and hour 17 (col 18)
poisson_samples[, 9]  <- normal_samples[, 1]
poisson_samples[, 18] <- normal_samples[, 2]

daily_totals <- rowSums(poisson_samples)
mean_daily <- mean(daily_totals)
sd_daily   <- sd(daily_totals)

list(
  mean_daily = mean_daily,
  sd_daily   = sd_daily
)
```
The average number of cars that pass that intersection per day is ~264 +- 13 cars.


## Problem 3

### a. Deidentify data

```{r}
youtube <- read.csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-03-02/youtube.csv')
dim(youtube)
colnames(youtube)
youtube1 <- youtube[, -c( 2, 3, 4, 12, 14, 20, 21, 22, 23,24)]
dim(youtube1)
colnames(youtube1)
head(youtube1)
```

I removed all identifiers from the list, the matrix became 247 rows and down to 15 columns from an initial 25-column matrix

### b. variables to be used in regression models

```{r}
hist(youtube1$view_count)
summary(youtube1$view_count)
hist(youtube1$like_count)
summary(youtube1$like_count)
hist(youtube1$dislike_count)
summary(youtube1$dislike_count)
hist(youtube1$favorite_count)
summary(youtube1$favorite_count)
hist(youtube1$comment_count)
summary(youtube1$comment_count)
```

Favorite count could not be appropriate to use as the outcome in a linear regression model since all the values are 0 (maybe binary). All other variables could be used as is as the outcome in a linear regression model.


### c. linear regression models

```{r}
#views
model_views <- lm(view_count ~ funny + show_product_quickly + patriotic + celebrity +
                  danger + animals + use_sex + year, data = youtube1)

summary(model_views)

#likes
model_likes <- lm(like_count ~ funny + show_product_quickly + patriotic + celebrity +
                  danger + animals + use_sex + year, data = youtube1)

summary(model_likes)

#dislikes
model_dislikes <- lm(dislike_count ~ funny + show_product_quickly + patriotic +    celebrity + danger + animals + use_sex + year, data = youtube1)

summary(model_dislikes)

#comments
model_comments <- lm(comment_count ~ funny + show_product_quickly + patriotic + celebrity + danger + animals + use_sex + year, data = youtube1)

summary(model_comments)
```

For the view, like and dislike counts, there is no statistcial difference based on the p-values > 0.05, thus no consistent effect between any of the binary variables and the view_count. 

However, for the comment counts there is a directly positive relationship between patriotic adds and comments with a p value of 0.035. This is the only statistically significantly relationship. 


### d. compute B hat manually

```{r}
# setting up proper matrix
vars_used <- c("view_count", "funny", "show_product_quickly", "patriotic", "celebrity",
               "danger", "animals", "use_sex", "year")
complete_cases <- complete.cases(youtube1[, vars_used])
youtube_complete <- youtube1[complete_cases, ]

X <- model.matrix(view_count ~ funny + show_product_quickly + patriotic + celebrity +
                 danger + animals + use_sex + year, data = youtube_complete)

y <- youtube_complete$view_count

cat("Dimensions of X:", dim(X), "\n")
cat("Length of y:", length(y), "\n")
cat("Number of rows in X equals length of y:", nrow(X) == length(y), "\n")

beta_hat_manual <- solve(crossprod(X), crossprod(X, y))
beta_hat_manual
```

These are same values of B obtained in part C when lm was used.
